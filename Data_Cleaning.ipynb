{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo3bjjc6au3H",
        "outputId": "a7d090d2-3a14-4e07-f741-3c29f23f94f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WlOlikVuJur",
        "outputId": "df8b85e5-9395-4280-bd25-eeed70c9733d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/15YNZD2LecLX-_msvWsjK7M14QTcshR8q/HTSS-master\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/CS685/HTSS-master"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "!pip install gputil\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-0bwtZovYLD",
        "outputId": "6514b2a3-55b8-4ecb-812a-c06001fe88d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python clean_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV5p6-P7ueKe",
        "outputId": "1100dc57-8b96-4495-bf21-a856dc0fb8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'clean_data.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ssd_data = pd.read_csv('ssd-chunked', sep='^').dropna()\n",
        "\n",
        "articles = ssd_data['article'].tolist()\n",
        "summaries = ssd_data['summary'].tolist()"
      ],
      "metadata": {
        "id": "aWcgm9BGvE5S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "print('No. of articles', len(articles))\n",
        "print('No. of summaries', len(summaries))\n",
        "\n",
        "avg_article_len = 0\n",
        "words_per_article = 0\n",
        "for article in articles:\n",
        "    avg_article_len += len(article)\n",
        "    words_per_article = words_per_article + len(word_tokenize(article))\n",
        "\n",
        "words_per_article = words_per_article / len(articles)\n",
        "\n",
        "print('Avg. Article Len: {}'.format(avg_article_len / len(articles)))\n",
        "print('Avg. number of words in a Article Len: {}'.format(words_per_article))\n",
        "\n",
        "avg_summary_len = 0\n",
        "for summary in summaries:\n",
        "    avg_summary_len += len(summary)\n",
        "\n",
        "print('Avg. Summary Len: {}'.format(avg_summary_len / len(summaries)))"
      ],
      "metadata": {
        "id": "6G9ac-XRjt0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ce9966-ef24-413e-c0f9-d43172e32f01"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "No. of articles 4052\n",
            "No. of summaries 4052\n",
            "Avg. Article Len: 12259.056762092794\n",
            "Avg. number of words in a Article Len: 2087.812191510365\n",
            "Avg. Summary Len: 3833.5804540967424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_length_list = []\n",
        "for article in articles:\n",
        "  word_length = len(word_tokenize(article))\n",
        "  word_length_list.append(word_length)\n",
        "word_length_list.sort()\n",
        "#90th percentile input length calculation\n",
        "index_of_90th_percentile = 0.9*len(articles)\n",
        "print(word_length_list[round(index_of_90th_percentile)])"
      ],
      "metadata": {
        "id": "wfmWKueskkQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f47474-8ed0-4735-d2d2-972687f510a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3645\n"
          ]
        }
      ]
    }
  ]
}